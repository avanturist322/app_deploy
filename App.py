import streamlit as st
import matplotlib.pyplot as plt
import numpy as np
from tqdm import tqdm
import copy

import source


#################################################################################################################
def run():
    random_state = 322
    metrics = source.Metrics()

    st.set_page_config(
        page_title="ÐŸÑ€Ð¾Ð³Ð½Ð¾Ð· Ñ‚ÐµÐ¿Ð»Ð¾Ð²Ñ‹Ñ… ÑÐ²Ð¾Ð¹ÑÑ‚Ð² Ð³Ð¾Ñ€Ð½Ñ‹Ñ… Ð¿Ð¾Ñ€Ð¾Ð´ Ð¿Ð¾ Ð´Ð°Ð½Ð½Ñ‹Ð¼ Ð“Ð˜Ð¡",
        page_icon="ðŸ–¥",
    )

    st.title("ÐŸÑ€Ð¾Ð³Ð½Ð¾Ð· Ñ‚ÐµÐ¿Ð»Ð¾Ð²Ñ‹Ñ… ÑÐ²Ð¾Ð¹ÑÑ‚Ð² Ð³Ð¾Ñ€Ð½Ñ‹Ñ… Ð¿Ð¾Ñ€Ð¾Ð´ Ð¿Ð¾ Ð´Ð°Ð½Ð½Ñ‹Ð¼ Ð“Ð˜Ð¡")

    st.write(r"Ð”Ð°Ð½Ð½Ð¾Ðµ Ð¿Ñ€Ð¸Ð»Ð¾Ð¶ÐµÐ½Ð¸Ðµ Ð¿Ñ€ÐµÐ´Ð½Ð°Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¾ Ð´Ð»Ñ Ð¾ÑÑƒÑ‰ÐµÑÑ‚Ð²Ð»ÐµÐ½Ð¸Ñ Ð¿Ñ€Ð¾Ð³Ð½Ð¾Ð·Ð° Ñ‚ÐµÐ¿Ð»Ð¾Ð²Ñ‹Ñ… ÑÐ²Ð¾Ð¹ÑÑ‚Ð² Ð³Ð¾Ñ€Ð½Ñ‹Ñ… Ð¿Ð¾Ñ€Ð¾Ð´ \
             ($\lambda_{\parallel}, \lambda_{\bot}, C_p$) Ð¿Ð¾ Ð´Ð°Ð½Ð½Ñ‹Ð¼ Ð³ÐµÐ¾Ñ„Ð¸Ð·Ð¸Ñ‡ÐµÑÐºÐ¸Ñ… Ð¸ÑÑÐ»ÐµÐ´Ð¾Ð²Ð°Ð½Ð¸Ð¹ ÑÐºÐ²Ð°Ð¶Ð¸Ð½ (Ð“Ð˜Ð¡).")

    st.sidebar.success("Ð’ Ð´Ð°Ð½Ð½Ð¾Ð¼ Ñ€Ð°Ð·Ð´ÐµÐ»Ðµ Ð¾ÑÑƒÑ‰ÐµÑÑ‚Ð²Ð»ÑÐµÑ‚ÑÑ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð²Ñ…Ð¾Ð´Ð½Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…, \
                     Ð¸Ñ… Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ°Ñ Ð¿Ñ€ÐµÐ´Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð¸ Ð¾ÑÑƒÑ‰ÐµÑÑ‚Ð²Ð»ÐµÐ½Ð¸Ðµ Ð¿Ñ€Ð¾Ð³Ð½Ð¾Ð·Ð° \
                     Ñ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸ÐµÐ¼ Ñ€Ð°Ð·Ð»Ð¸Ñ‡Ð½Ñ‹Ñ… Ð°Ð»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼Ð¾Ð² ML Ñ ÑƒÐ¿Ñ€Ð°Ð²Ð»ÑÐµÐ¼Ð¾Ð¹ \
                     Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¾Ð¹ Ð¾ÑÐ½Ð¾Ð²Ð½Ñ‹Ñ… Ð³Ð¸Ð¿ÐµÑ€Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð¾Ð².")
    st.sidebar.info(r"**Ð’Ð°Ð¶Ð½Ð¾:** Ð´Ð»Ñ Ð¾ÑÑƒÑ‰ÐµÑÑ‚Ð²Ð»ÐµÐ½Ð¸Ñ Ð¿Ñ€Ð¾Ð³Ð½Ð¾Ð·Ð° $\lambda_{\bot}$ Ð¸Ð»Ð¸ $K$ ÑÐ½Ð°Ñ‡Ð°Ð»Ð° Ð²Ñ‹Ð¿Ð¾Ð»Ð½Ð¸Ñ‚Ðµ Ð¿Ñ€Ð¾Ð³Ð½Ð¾Ð· $\lambda_{\parallel}$ Ð¸ ÑÐ¾Ñ…Ñ€Ð°Ð½Ð¸Ñ‚Ðµ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚, Ð° Ð¿Ð¾Ñ‚Ð¾Ð¼ Ð·Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚Ðµ ÐµÐ³Ð¾ Ð² ÑÐ¾Ð¾Ñ‚Ð²ÐµÑ‚ÑÑ‚Ð²ÑƒÑŽÑ‰ÐµÐ¼ Ð¾ÐºÐ½Ðµ.")


    st.write("### 1. Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð´Ð°Ð½Ð½Ñ‹Ñ…")
    st.write("Ð—Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚Ðµ Ð²Ñ…Ð¾Ð´Ð½Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð² Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ðµ `.csv` Ð¸Ð»Ð¸ `.xlsx`.")
    st.info("Ð’Ð°Ð¼ Ð½Ðµ Ð½ÑƒÐ¶Ð½Ð¾ ÑƒÐ¿Ð¾Ñ€ÑÐ´Ð¾Ñ‡Ð¸Ð²Ð°Ñ‚ÑŒ ÐºÐ¾Ð»Ð¾Ð½ÐºÐ¸ Ð² Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ð°Ñ… / \
            Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÑŒ Ð½Ð°Ð·Ð²Ð°Ð½Ð¸Ñ ÐºÐ°Ðº Ð² Ð¿Ñ€Ð¸Ð¼ÐµÑ€Ð°Ñ… - Ð¿Ñ€Ð¸ Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ð¸ ÑÐ¾Ð¾Ñ‚Ð²ÐµÑ‚ÑÑ‚Ð²ÑƒÑŽÑ‰ÐµÐ³Ð¾ \
            ÑˆÐ°Ð³Ð° Ð±ÑƒÐ´ÐµÑ‚ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð° Ð²Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ð¾ÑÑ‚ÑŒ ÑƒÐºÐ°Ð·Ð°Ñ‚ÑŒ Ð½Ð°Ð·Ð²Ð°Ð½Ð¸Ðµ \
            ÐºÐ¾Ð»Ð¾Ð½ÐºÐ¸ Ñ Ð¿Ñ€Ð¾Ð³Ð½Ð¾Ð·Ð¸Ñ€ÑƒÐµÐ¼Ð¾Ð¹ Ð²ÐµÐ»Ð¸Ñ‡Ð¸Ð½Ð¾Ð¹, Ð³Ð»ÑƒÐ±Ð¸Ð½Ð¾Ð¹ Ð¸Ð»Ð¸ Ñ‚Ð¸Ð¿Ð¾Ð¼ Ð¿Ð¾Ñ€Ð¾Ð´. \
            **Ð’Ð°Ð¶Ð½Ð¾**: Ð½Ð°Ð·Ð²Ð°Ð½Ð¸Ñ ÐºÐ¾Ð»Ð¾Ð½Ð¾Ðº Ñ Ð³Ð»ÑƒÐ±Ð¸Ð½Ð¾Ð¹ Ð¸ Ñ‚Ð¸Ð¿Ð°Ð¼Ð¸ Ð¿Ð¾Ñ€Ð¾Ð´ \
            Ð² Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ð°Ñ… Ð² Ñ€Ð°Ð·Ð´ÐµÐ»Ð°Ñ… 1.1. Ð¸ 1.2. Ð´Ð¾Ð»Ð¶Ð½Ñ‹ Ð±Ñ‹Ñ‚ÑŒ Ð¾Ð´Ð¸Ð½Ð°ÐºÐ¾Ð²Ñ‹.")
    st.write("#### 1.1. Ð”Ð°Ð½Ð½Ñ‹Ðµ Ð“Ð˜Ð¡")
    st.info("Ð—Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚Ðµ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñƒ, ÑÐ¾Ð´ÐµÑ€Ð¶Ð°Ð·ÑƒÑŽ ÐºÐ¾Ð»Ð¾Ð½ÐºÑƒ Ñ Ð³Ð»ÑƒÐ±Ð¸Ð½Ð¾Ð¹, ÐºÐ¾Ð»Ð¾Ð½ÐºÐ¸ Ñ \
            Ð´Ð°Ð½Ð½Ñ‹Ð¼Ð¸ Ð“Ð˜Ð¡ Ð¸ (Ð¾Ð¿Ñ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾) ÐºÐ¾Ð»Ð¾Ð½ÐºÑƒ Ñ Ñ‚Ð¸Ð¿Ð°Ð¼Ð¸ Ð¿Ð¾Ñ€Ð¾Ð´. Ð¢Ð°Ð±Ð»Ð¸Ñ†Ð° \
            Ð´Ð¾Ð»Ð¶Ð½Ð° Ð±Ñ‹Ñ‚ÑŒ Ð¾Ñ‚ÑÐ¾Ñ€Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð° Ð¿Ð¾ Ð²Ð¾Ð·Ñ€Ð°ÑÑ‚Ð°Ð½Ð¸ÑŽ Ð³Ð»ÑƒÐ±Ð¸Ð½Ñ‹ Ñ Ð¿Ñ€Ð¸Ð²ÐµÐ´ÐµÐ½Ð½Ñ‹Ð¼Ð¸ \
            Ðº Ð¾Ð´Ð½Ð¾Ð¹ Ð³Ð»ÑƒÐ±Ð¸Ð½Ðµ Ð´Ð°Ð½Ð½Ñ‹Ð¼Ð¸ Ð“Ð˜Ð¡.")
    
    st.info(r"**ÐŸÑ€Ð¸Ð¼ÐµÑ€ ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ð¸ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñ‹** \
            Ð“Ð»ÑƒÐ±Ð¸Ð½Ð° | Ð“Ð˜Ð¡-1 | Ð“Ð˜Ð¡-2 | ... | Ð“Ð˜Ð¡-n| Ð¢Ð¸Ð¿ Ð¿Ð¾Ñ€Ð¾Ð´ (Ð¾Ð¿Ñ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾)")
    
    uploaded_gis = st.file_uploader("TC_par", 
                                     type=['csv', 'xlsx'], 
                                     label_visibility='collapsed')
    ALL_GIS = source.load_file_to_st(uploaded_gis)

    st.write("#### 1.2. Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ Ð¸Ð·Ð¼ÐµÑ€ÐµÐ½Ð¸Ð¹ Ð½Ð° ÐºÐµÑ€Ð½Ðµ")
    st.info("Ð—Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚Ðµ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñƒ, ÑÐ¾Ð´ÐµÑ€Ð¶Ð°Ñ‰ÑƒÑŽ ÐºÐ¾Ð»Ð¾Ð½ÐºÑƒ Ñ Ð³Ð»ÑƒÐ±Ð¸Ð½Ð¾Ð¹, ÐºÐ¾Ð»Ð¾Ð½ÐºÐ¸ Ñ \
            Ð¿Ñ€ÐµÐ´Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð½Ð½Ñ‹Ð¼Ð¸ (ÑÐºÐ¾Ñ€Ñ€ÐµÐºÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¼Ð¸ Ð½Ð° Ð¿Ð»Ð°ÑÑ‚Ð¾Ð²Ñ‹Ðµ ÑƒÑÐ»Ð¾Ð²Ð¸Ñ \
            / upscaled) Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸ÑÐ¼Ð¸ Ð¿Ñ€Ð¾Ð³Ð½Ð¾Ð·Ð¸Ñ€ÑƒÐµÐ¼Ñ‹Ñ… Ð²ÐµÐ»Ð¸Ñ‡Ð¸Ð½.")
    st.info(r"**ÐŸÑ€Ð¸Ð¼ÐµÑ€Ñ‹ Ð¼Ð¸Ð½Ð¸Ð¼Ð°Ð»ÑŒÐ½Ñ‹Ñ… ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ð¹ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñ‹** \
            1. Ð”Ð»Ñ Ð¿Ñ€Ð¾Ð³Ð½Ð¾Ð·Ð° $\lambda_{\parallel}$ Ð¸Ð»Ð¸ $C_p$: \
            Ð“Ð»ÑƒÐ±Ð¸Ð½Ð° | $\lambda_{\parallel}$ / $C_p$| Ð¢Ð¸Ð¿ Ð¿Ð¾Ñ€Ð¾Ð´ (Ð¾Ð¿Ñ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾) \
            2. Ð”Ð»Ñ Ð¿Ñ€Ð¾Ð³Ð½Ð¾Ð·Ð° $\lambda_{\bot}$ Ð¸Ð»Ð¸ $K$: \
            Ð“Ð»ÑƒÐ±Ð¸Ð½Ð° | $\lambda_{\parallel}$ | $K$| Ð¢Ð¸Ð¿ Ð¿Ð¾Ñ€Ð¾Ð´ (Ð¾Ð¿Ñ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾)")

    uploaded_data = st.file_uploader("data", 
                                     type=['csv', 'xlsx'], 
                                     label_visibility='collapsed')
    data = source.load_file_to_st(uploaded_data)
    
    use_lith = st.checkbox('Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÑŒ Ñ‚Ð¸Ð¿Ñ‹ Ð¿Ð¾Ñ€Ð¾Ð´ Ð¿Ñ€Ð¸ Ð¿Ñ€Ð¾Ð³Ð½Ð¾Ð·Ðµ?', value=False)
    lith_name = st.text_input("Ð’Ð²ÐµÐ´Ð¸Ñ‚Ðµ Ð½Ð°Ð·Ð²Ð°Ð½Ð¸Ðµ ÐºÐ¾Ð»Ð¾Ð½ÐºÐ¸ Ñ Ñ‚Ð¸Ð¿Ð°Ð¼Ð¸ Ð¿Ð¾Ñ€Ð¾Ð´, ÐµÑÐ»Ð¸ Ð¾Ð½Ð° ÐµÑÑ‚ÑŒ Ð² Ð´Ð°Ð½Ð½Ñ‹Ñ…:", "ÐšÐ¾Ð´ Prime")
    if use_lith:
        st.info("Ð‘ÑƒÐ´ÑƒÑ‚ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ñ‹ Ñ‚Ð¸Ð¿Ñ‹ Ð¿Ð¾Ñ€Ð¾Ð´.")
        # lith_name = st.text_input("Ð’Ð²ÐµÐ´Ð¸Ñ‚Ðµ Ð½Ð°Ð·Ð²Ð°Ð½Ð¸Ðµ ÐºÐ¾Ð»Ð¾Ð½ÐºÐ¸ Ñ Ñ‚Ð¸Ð¿Ð°Ð¼Ð¸ Ð¿Ð¾Ñ€Ð¾Ð´:", "ÐšÐ¾Ð´ Prime")
        st.write(f"Ð’Ñ‹Ð±Ñ€Ð°Ð½Ð° ÐºÐ¾Ð»Ð¾Ð½ÐºÐ° {lith_name} Ñ Ñ‚Ð¸Ð¿Ð°Ð¼Ð¸ Ð¿Ð¾Ñ€Ð¾Ð´.")

        assert lith_name in ALL_GIS.columns.values, 'Ð’ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð½ÐµÑ‚ Ñ‚Ð°ÐºÐ¾Ð¹ ÐºÐ¾Ð»Ð¾Ð½ÐºÐ¸ Ñ Ñ‚Ð¸Ð¿Ð°Ð¼Ð¸ Ð¿Ð¾Ñ€Ð¾Ð´'

        fig, ax = plt.subplots(1, 2, figsize=(12,5))
        
        ax[0].hist(data.sort_values(by=lith_name)[lith_name].astype(int).astype(str), bins=20)
        ax[1].hist(ALL_GIS.sort_values(by=lith_name)[lith_name].astype(int).astype(str), bins=20)
        
        ax[0].xaxis.set_tick_params(rotation=45)
        ax[1].xaxis.set_tick_params(rotation=45)

        st.pyplot(fig)

    else:
        st.info("Ð¢Ð¸Ð¿Ñ‹ Ð¿Ð¾Ñ€Ð¾Ð´ Ð½Ðµ Ð±ÑƒÐ´ÑƒÑ‚ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ñ‹.")


    # * Ð£Ð´Ð°Ð»ÐµÐ½Ð¸Ðµ Ð¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ð²ÑƒÑŽÑ‰Ð¸Ñ… Ð² Ð¾Ð±ÑƒÑ‡Ð°ÑŽÑ‰ÐµÐ¹ Ð²Ñ‹Ð±Ð¾Ñ€ÐºÐµ Ñ‚Ð¸Ð¿Ð¾Ð² Ð¿Ð¾Ñ€Ð¾Ð´

    if use_lith:
        shape_before = ALL_GIS.shape
        ALL_GIS = ALL_GIS[ALL_GIS[lith_name].isin(data[lith_name])].reset_index(drop=True)
        shape_after = ALL_GIS.shape
        st.write(f"Ð Ð°Ð·Ð¼ÐµÑ€ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñ‹ Ñ Ð´Ð°Ð½Ð½Ñ‹Ð¼Ð¸ Ð“Ð˜Ð¡ Ð´Ð¾ Ð¸ÑÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ñ Ð½Ðµ Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÐµÐ½Ð½Ñ‹Ñ… \
                 Ð¾Ð±Ñ€Ð°Ð·Ñ†Ð°Ð¼Ð¸ ÐºÐµÑ€Ð½Ð° Ñ‚Ð¸Ð¿Ð¾Ð² Ð¿Ð¾Ñ€Ð¾Ð´:")
        st.write(shape_before)
        st.write(f"Ð Ð°Ð·Ð¼ÐµÑ€ Ð¿Ð¾ÑÐ»Ðµ Ð¸ÑÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ñ:")
        st.write(shape_after)

        fig, ax = plt.subplots(1, 2, figsize=(12,5))
        
        ax[0].hist(data.sort_values(by=lith_name)[lith_name].astype(int).astype(str), bins=20)
        ax[1].hist(ALL_GIS.sort_values(by=lith_name)[lith_name].astype(int).astype(str), bins=20)
        
        ax[0].xaxis.set_tick_params(rotation=45)
        ax[1].xaxis.set_tick_params(rotation=45)

        st.pyplot(fig)



    # * Ð Ð°Ð·Ð±Ð¸ÐµÐ½Ð¸Ðµ Ð½Ð° Ð¾Ð±ÑƒÑ‡Ð°ÑŽÑ‰ÑƒÑŽ Ð¸ Ñ‚ÐµÑÑ‚Ð¾Ð²ÑƒÑŽ Ð²Ñ‹Ð±Ð¾Ñ€ÐºÐ¸
    depth_name = st.text_input("Ð’Ð²ÐµÐ´Ð¸Ñ‚Ðµ Ð½Ð°Ð·Ð²Ð°Ð½Ð¸Ðµ ÐºÐ¾Ð»Ð¾Ð½ÐºÐ¸ Ñ Ð³Ð»ÑƒÐ±Ð¸Ð½Ð¾Ð¹:", "DEPT")
    st.write(f"Ð’Ñ‹Ð±Ñ€Ð°Ð½Ð° ÐºÐ¾Ð»Ð¾Ð½ÐºÐ° {depth_name} Ñ Ð³Ð»ÑƒÐ±Ð¸Ð½Ð°Ð¼Ð¸.")

    from sklearn.model_selection import train_test_split
    import pandas as pd

    feature_names = ALL_GIS.columns.values.tolist()
    feature_names.remove(depth_name)

    if not use_lith:# and lith_name is not None:
        feature_names.remove(lith_name)
    
    st.write("ÐŸÑ€Ð¸Ð·Ð½Ð°ÐºÐ¸:")
    st.write(feature_names)


    # ? ÐÐ° ÑÑ‚Ð¾Ð¼ ÑÑ‚Ð°Ð¿Ðµ ÐµÑÑ‚ÑŒ Ð½Ð°Ð·Ð²Ð°Ð½Ð¸Ñ ÐºÐ¾Ð»Ð¾Ð½Ð¾Ðº Ñ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ°Ð¼Ð¸ Ñ Ð¸Ð»Ð¸ Ð±ÐµÐ· Ð»Ð¸Ñ‚Ð¾Ñ‚Ð¸Ð¿Ð¾Ð²
    all_gis = ALL_GIS.copy()
    if lith_name in ALL_GIS.columns.values: 
        all_gis = all_gis.drop(lith_name, axis=1)
    
    final_list = {}
    for col_name in all_gis.columns.values:
        if col_name == depth_name:
            continue
        else:
            final_list[col_name] = all_gis[[depth_name, col_name]]


    df_new4 = data.copy()
    min_depth, max_depth = ALL_GIS[depth_name].min(), ALL_GIS[depth_name].max()
    df_new4 = df_new4[(df_new4[depth_name] >= min_depth) \
                        & (df_new4[depth_name] <= max_depth)].reset_index(drop=True)
    
    for key in tqdm(final_list.keys()):
        selected_b = final_list[key][(final_list[key]['DEPT'] >= data['DEPT'].min()) & (final_list[key]['DEPT'] <= data['DEPT'].max())]
        new_y2 = np.interp(data['DEPT'], selected_b['DEPT'], selected_b[final_list[key].columns.values[1]])
        result = pd.DataFrame({final_list[key].columns.values[1]: new_y2})
        df_new4 = pd.concat([df_new4, result], axis=1)

    data_to_pred = df_new4.copy()
        
    st.success("Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ Ð¸Ð½Ñ‚ÐµÑ€Ð¿Ð¾Ð»ÑÑ†Ð¸Ð¸ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð“Ð˜Ð¡ Ð¿Ð¾ Ð³Ð»ÑƒÐ±Ð¸Ð½Ð°Ð¼ ÐºÐµÑ€Ð½Ð¾Ð²Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…")
    st.write(data_to_pred)

    # !  ===================================  ÐŸÐ ÐžÐ“ÐÐžÐ— Ð¢Ð•ÐŸÐ›ÐžÐ’Ð«Ð¥ Ð¡Ð’ÐžÐ™Ð¡Ð¢Ð’ ==========================================
    st.write("### 2. ÐŸÑ€Ð¾Ð³Ð½Ð¾Ð· Ñ‚ÐµÐ¿Ð»Ð¾Ð²Ñ‹Ñ… ÑÐ²Ð¾Ð¹ÑÑ‚Ð²")
    st.write("Ð§Ñ‚Ð¾ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ñ‹Ð²Ð°ÐµÐ¼?")

    what_to_predict = st.selectbox("ÐŸÑ€ÐµÐ´ÑÐºÐ°Ð·Ñ‹Ð²Ð°Ñ‚ÑŒ: ", 
                                    ("TC_par", 
                                    "TC_per",
                                    "VHC"))
    
    st.info(f"ÐšÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ñ Ð¿Ñ€Ð¾Ð³Ð½Ð¾Ð·Ð°: {what_to_predict}")

    
    # !  ................................  ÐŸÐ ÐžÐ“ÐÐžÐ— TC_par | VHC ........................................

    # go = st.checkbox("Ð•Ð´ÐµÐ¼ Ð´Ð°Ð»ÑŒÑˆÐµ?", True)
    # if go or not go:
    #     st.write(1)

    if what_to_predict == 'TC_par':
        tc_par_name = st.text_input(r"Ð’Ð²ÐµÐ´Ð¸Ñ‚Ðµ Ð½Ð°Ð·Ð²Ð°Ð½Ð¸Ðµ ÐºÐ¾Ð»Ð¾Ð½ÐºÐ¸ Ñ $\lambda_{\parallel}$:", "TC_par_ups")
        st.info(f"ÐŸÑ€Ð¾Ð³Ð½Ð¾Ð·Ð¸Ñ€ÑƒÐµÐ¼Ð°Ñ Ð²ÐµÐ»Ð¸Ñ‡Ð¸Ð½Ð°: {tc_par_name}")
    elif what_to_predict == 'TC_per':
        anisotropy_name = st.text_input(r"Ð’Ð²ÐµÐ´Ð¸Ñ‚Ðµ Ð½Ð°Ð·Ð²Ð°Ð½Ð¸Ðµ ÐºÐ¾Ð»Ð¾Ð½ÐºÐ¸ Ñ $K = \frac{\lambda_{\parallel}}{\lambda_{\bot}}$:", "Anisotropy_ups")
        tc_par_name = st.text_input(r"Ð’Ð²ÐµÐ´Ð¸Ñ‚Ðµ Ð½Ð°Ð·Ð²Ð°Ð½Ð¸Ðµ ÐºÐ¾Ð»Ð¾Ð½ÐºÐ¸ Ñ $\lambda_{\parallel}$:", "TC_par_ups")
        tc_per_name = st.text_input(r"Ð’Ð²ÐµÐ´Ð¸Ñ‚Ðµ Ð½Ð°Ð·Ð²Ð°Ð½Ð¸Ðµ ÐºÐ¾Ð»Ð¾Ð½ÐºÐ¸ Ñ $\lambda_{\bot}$:", "TC_per_ups")
        st.info(rf"ÐŸÑ€Ð¾Ð³Ð½Ð¾Ð·Ð¸Ñ€ÑƒÐµÐ¼Ð°Ñ Ð²ÐµÐ»Ð¸Ñ‡Ð¸Ð½Ð°: {anisotropy_name}, Ð¿Ð¾ÑÐ»ÐµÐ´ÑƒÑŽÑ‰Ð¸Ð¹ Ð¿ÐµÑ€ÐµÑ€Ð°ÑÑ‡ÐµÑ‚ Ð² TC_per")
    elif what_to_predict == 'VHC':
        vhc_name = st.text_input(r"Ð’Ð²ÐµÐ´Ð¸Ñ‚Ðµ Ð½Ð°Ð·Ð²Ð°Ð½Ð¸Ðµ ÐºÐ¾Ð»Ð¾Ð½ÐºÐ¸ Ñ $C_p$:", "VHC_ups")
        st.info(f"ÐŸÑ€Ð¾Ð³Ð½Ð¾Ð·Ð¸Ñ€ÑƒÐµÐ¼Ð°Ñ Ð²ÐµÐ»Ð¸Ñ‡Ð¸Ð½Ð°: {vhc_name}")
        

    
    if what_to_predict == 'TC_par':
        data_to_pred = data_to_pred[[depth_name] + feature_names + [tc_par_name]].dropna().reset_index(drop=True)
        if use_lith:
            unique_value_counts = data_to_pred[lith_name].value_counts()
            need_to_replicate = unique_value_counts[unique_value_counts<=2].index.values
            for val in need_to_replicate:
                data_to_pred = pd.concat((data_to_pred, data_to_pred[data_to_pred[lith_name] == val]), axis=0).reset_index(drop=True)
        y = data_to_pred[tc_par_name]
        mode_pred = 'tc_par'
        X = data_to_pred[feature_names]

    elif what_to_predict == 'TC_per':
        data_to_tc_par = data_to_pred[[depth_name] + feature_names + [tc_par_name]].dropna().reset_index(drop=True)
        if use_lith:
            unique_value_counts = data_to_tc_par[lith_name].value_counts()
            need_to_replicate = unique_value_counts[unique_value_counts<=2].index.values
            for val in need_to_replicate:
                data_to_tc_par = pd.concat((data_to_tc_par, data_to_tc_par[data_to_tc_par[lith_name] == val]), axis=0).reset_index(drop=True)
        y_to_tc_par = data_to_tc_par[tc_par_name]
        X_to_tc_par = data_to_tc_par[feature_names]
        Dept_to_tc_par = data_to_tc_par[depth_name]

        data_to_pred = data_to_pred[[depth_name] + feature_names + [anisotropy_name] + [tc_par_name] + [tc_per_name]].dropna().reset_index(drop=True)
        if use_lith:
            unique_value_counts = data_to_pred[lith_name].value_counts()
            need_to_replicate = unique_value_counts[unique_value_counts<=2].index.values
            for val in need_to_replicate:
                data_to_pred = pd.concat((data_to_pred, data_to_pred[data_to_pred[lith_name] == val]), axis=0).reset_index(drop=True)
        y = data_to_pred[anisotropy_name]
        mode_pred = 'anisotropy'
        X = data_to_pred[feature_names + [tc_par_name]]

    elif what_to_predict == 'VHC':
        data_to_pred = data_to_pred[[depth_name] + feature_names + [vhc_name]].dropna().reset_index(drop=True)
        if use_lith:
            unique_value_counts = data_to_pred[lith_name].value_counts()
            need_to_replicate = unique_value_counts[unique_value_counts<=2].index.values
            for val in need_to_replicate:
                data_to_pred = pd.concat((data_to_pred, data_to_pred[data_to_pred[lith_name] == val]), axis=0).reset_index(drop=True)
        y = data_to_pred[vhc_name]
        mode_pred = 'vhc'
        X = data_to_pred[feature_names]


        
    Dept = data_to_pred[depth_name]

    def df_to_csv(df, filename, button_text, add_key=''):
        @st.cache_data
        def convert_df(df):
            return df.to_csv(index=False).encode('utf-8')


        csv = convert_df(df)

        st.download_button(f"{button_text}", # label
                            csv, # data
                            f"{filename}.csv", # filename
                            "text/csv",
                            key='download-csv'+add_key)
    

    if use_lith:
        X_train_orig, X_test_orig, \
            y_train_tc_par, y_test_tc_par, \
            Dept_train_tc_par, Dept_test_tc_par = train_test_split(X, y, Dept, test_size=0.3, 
                                                            random_state=random_state, 
                                                            shuffle=True, stratify=X[lith_name])

        feature_names2 = copy.deepcopy(feature_names)
        feature_names2.remove(lith_name)

        X_train_combined, X_test_combined, \
            ALL_GIS_combined, scaler = source.get_preprocessed_data(X_train_orig, X_test_orig, 
                                                                    ALL_GIS, mode='ss', do_ohe=True,
                                                                    lith_name=lith_name, mode_pred=mode_pred,
                                                                    feature_names=feature_names2, 
                                                                    tc_par_name=tc_par_name if what_to_predict != 'VHC' else '')
    else:
        X_train_orig, X_test_orig, \
        y_train_tc_par, y_test_tc_par, \
        Dept_train_tc_par, Dept_test_tc_par = train_test_split(X, y, Dept, test_size=0.3, 
                                                        random_state=random_state, 
                                                        shuffle=True)#, stratify=X[lith_name])

        from sklearn.preprocessing import StandardScaler
        scaler = StandardScaler()
        scaler.fit(X_train_orig)
        X_train_combined = scaler.transform(X_train_orig)
        X_test_combined = scaler.transform(X_test_orig)
        
        try:
            ALL_GIS_combined = scaler.transform(ALL_GIS.drop(columns=[depth_name, lith_name]))
        except:
            st.write(r"Ð”Ð»Ñ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð¿Ñ€Ð¾Ð³Ð½Ð¾Ð·Ð° $\lambda_{\bot}$ Ð½Ð° Ð²ÐµÑÑŒ Ð¸Ð½Ñ‚ÐµÑ€Ð²Ð°Ð», Ð·Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚Ðµ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð½Ñ‹Ð¹ Ñ€Ð°Ð½ÐµÐµ Ð¿Ñ€Ð¾Ð³Ð½Ð¾Ð· $\lambda_{\parallel}$ Ð¿Ð¾ Ð²ÑÐµÐ¼Ñƒ Ð¸Ð½Ñ‚ÐµÑ€Ð²Ð°Ð»Ñƒ:")
            uploaded_tc_par_pred = st.file_uploader("TC_par_pred", 
                                                    type=['csv', 'xlsx'], 
                                                    label_visibility='collapsed',
                                                    key='0')
            pred_all_tc_par = source.load_file_to_st(uploaded_tc_par_pred)

            
            ALL_GIS_combined = scaler.transform(pd.concat((ALL_GIS, pred_all_tc_par.iloc[:,-1]), axis=1).rename(columns={'TC_par_pred': tc_par_name}).drop(columns=[depth_name, lith_name]))



    # st.write(X_train_combined.shape, X_test_combined.shape, ALL_GIS.shape, ALL_GIS_combined.shape)

    # ? PREDICTOR
    model_mode = st.selectbox("Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ñ‚Ð¸Ð¿ Ð¼Ð¾Ð´ÐµÐ»Ð¸:", 
                ("Linear Regression",
                    "Decision Tree",
                    "Gradient Boosting", 
                    "XGBoost",
                    "CatBoost",
                    "Stacking"))
    
    st.info(f"Ð’Ñ‹Ð±Ñ€Ð°Ð½Ð½Ð°Ñ Ð¼Ð¾Ð´ÐµÐ»ÑŒ: {model_mode}")

    def predictor(pred_name):
        def display_title_metrics(pred_name):
            if pred_name == 'TC_par':
                st.write(r"ÐœÐµÑ‚Ñ€Ð¸ÐºÐ¸ Ð´Ð»Ñ $\lambda_{\parallel}$")
            elif pred_name == 'TC_per':
                st.write(r"ÐœÐµÑ‚Ñ€Ð¸ÐºÐ¸ Ð´Ð»Ñ $\lambda_{\bot}$")
            elif pred_name == 'Anisotropy':
                st.write(r"ÐœÐµÑ‚Ñ€Ð¸ÐºÐ¸ Ð´Ð»Ñ $K$")
            elif pred_name == 'VHC':
                st.write(r"ÐœÐµÑ‚Ñ€Ð¸ÐºÐ¸ Ð´Ð»Ñ $C_p$")
            elif pred_name is None:
                pass

        if model_mode == "Linear Regression":
            from sklearn.linear_model import LinearRegression
            model = LinearRegression()
            model.fit(X_train_combined, y_train_tc_par)
            y_pred_tc_par = model.predict(X_test_combined)
            pred_all_tc_par = model.predict(ALL_GIS_combined)
            if pred_name is not None:
                display_title_metrics(pred_name)
                source.get_metrics(y_test_tc_par, y_pred_tc_par)

        elif model_mode == "Decision Tree":
            from sklearn.tree import DecisionTreeRegressor

            params = {'max_depth': None, # None or int
                    'min_samples_split': 2,
                    'min_samples_leaf': 1}

            # Create sliders for non-None parameters
            for param, default in params.items():
                if param != 'max_depth':
                    if isinstance(default, int):
                        value = st.slider(f"{param}", 1, 20, default, key=f"dt_solo_{param}")
                    else:
                        value = st.selectbox(f"{param}", [None, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], key=f"dt_solo_{param}")
                else:
                    # value = st.selectbox(f"{param}", [None, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10])
                    value = st.slider(f"{param}", None, 20, default, key=f"dt_solo_{param}")
                    if value == 0:
                        value = None

                params[param] = value

            # Display selected parameters
            st.write("Selected Parameters:")
            st.write(params)
            params['random_state'] = 42

            model = DecisionTreeRegressor(**params)
            model.fit(X_train_combined, y_train_tc_par)
            y_pred_tc_par = model.predict(X_test_combined)
            pred_all_tc_par = model.predict(ALL_GIS_combined)
            if pred_name is not None:
                display_title_metrics(pred_name)
                source.get_metrics(y_test_tc_par, y_pred_tc_par)          

        elif model_mode == "Gradient Boosting":
            from sklearn.ensemble import GradientBoostingRegressor

            params = {'max_depth': 3, # None or int
                    'learning_rate': 0.01,
                    'n_estimators': 200}

            # Create sliders for non-None parameters
            for param, default in params.items():
                if param == 'max_depth':
                    value = st.slider(f"{param}", None, 20, default, step=1, key=f"gb_solo_{param}")
                    if value == 0:
                        value = None
                elif param == 'learning_rate':
                    value = st.slider(f"{param}", 0.01, 1.0, default, step=0.01, key=f"gb_solo_{param}")
                elif param == 'n_estimators':
                    value = st.slider(f"{param}", 0, 1000, default, step=10, key=f"gb_solo_{param}")
                    if value == 0:
                        value = 1

                params[param] = value

            # Display selected parameters
            st.write("Selected Parameters:")
            st.write(params)
            params['random_state'] = 42

            model = GradientBoostingRegressor(**params)
            model.fit(X_train_combined, y_train_tc_par)
            y_pred_tc_par = model.predict(X_test_combined)
            pred_all_tc_par = model.predict(ALL_GIS_combined)
            if pred_name is not None:
                display_title_metrics(pred_name)
                source.get_metrics(y_test_tc_par, y_pred_tc_par)

        elif model_mode == "XGBoost":
            import xgboost as xgb

            params = {'max_depth': 7, # None or int
                    'learning_rate': 0.5,
                    'n_estimators': 200}

            # Create sliders for non-None parameters
            for param, default in params.items():
                if param == 'max_depth':
                    value = st.slider(f"{param}", None, 20, default, step=1, key=f"xgb_solo_{param}")
                    if value == 0:
                        value = None
                elif param == 'learning_rate':
                    value = st.slider(f"{param}", 0.01, 1.0, default, step=0.01, key=f"xgb_solo_{param}")
                elif param == 'n_estimators':
                    value = st.slider(f"{param}", 0, 1000, default, step=10, key=f"xgb_solo_{param}")
                    if value == 0:
                        value = 1

                params[param] = value

            # Display selected parameters
            st.write("Selected Parameters:")
            st.write(params)
            params['random_state'] = 42

            model = xgb.XGBRegressor(**params)
            model.fit(X_train_combined, y_train_tc_par)
            y_pred_tc_par = model.predict(X_test_combined)
            pred_all_tc_par = model.predict(ALL_GIS_combined)
            if pred_name is not None:
                display_title_metrics(pred_name)
                source.get_metrics(y_test_tc_par, y_pred_tc_par) 

        elif model_mode == "CatBoost":
            from catboost import CatBoostRegressor

            params = {'depth': 7, # None or int
                    'learning_rate': 0.5,
                    'l2_leaf_reg': 5,
                    'iterations': 700}

            # Create sliders for non-None parameters
            for param, default in params.items():
                if param == 'depth':
                    value = st.slider(f"{param}", None, 20, default, step=1)
                    if value == 0:
                        value = None
                elif param == 'learning_rate':
                    value = st.slider(f"{param}", 0.01, 1.0, default, step=0.01)
                elif param == 'l2_leaf_reg':
                    value = st.slider(f"{param}", 0, 10, default, step=1)
                elif param == 'iterations':
                    value = st.slider(f"{param}", 0, 1000, default, step=10)
                    if value == 0:
                        value = 1

                params[param] = value

            # Display selected parameters
            st.write("Selected Parameters:")
            st.write(params)
            params['random_state'] = 42
            params['task_type'] = 'CPU'
            params['silent'] = True

            model = CatBoostRegressor(**params)
            model.fit(X_train_combined, y_train_tc_par)
            y_pred_tc_par = model.predict(X_test_combined)
            pred_all_tc_par = model.predict(ALL_GIS_combined)
            if pred_name is not None:
                display_title_metrics(pred_name)
                source.get_metrics(y_test_tc_par, y_pred_tc_par)

        elif model_mode == "Stacking":
            from sklearn.linear_model import LinearRegression
            from sklearn.ensemble import GradientBoostingRegressor
            import xgboost as xgb
            from catboost import CatBoostRegressor

            params_gb = {'max_depth': 3, # None or int
                    'learning_rate': 0.01,
                    'n_estimators': 200}
            
            params_xgb = {'depth': 7, # None or int
                    'learning_rate': 0.5,
                    'n_estimators': 200}

            params_cb = {'depth': 7, # None or int
                    'learning_rate': 0.5,
                    'l2_leaf_reg': 5,
                    'iterations': 700}


            st.write("Gradient Boosting")
            for param, default in params_gb.items():
                if param == 'max_depth':
                    value = st.slider(f"{param}", None, 20, default, step=1, key=f"gb_{param}")
                    if value == 0:
                        value = None
                elif param == 'learning_rate':
                    value = st.slider(f"{param}", 0.01, 1.0, default, step=0.01, key=f"gb_{param}")
                elif param == 'n_estimators':
                    value = st.slider(f"{param}", 0, 1000, default, step=10, key=f"gb_{param}")
                    if value == 0:
                        value = 1
                params_gb[param] = value

            st.write("XGBoost")
            for param, default in params_xgb.items():
                if param == 'depth':
                    value = st.slider(f"{param}", None, 20, default, step=1, key=f"xgb_{param}")
                    if value == 0:
                        value = None
                elif param == 'learning_rate':
                    value = st.slider(f"{param}", 0.01, 1.0, default, step=0.01, key=f"xgb_{param}")
                elif param == 'n_estimators':
                    value = st.slider(f"{param}", 0, 1000, default, step=10, key=f"xgb_{param}")
                    if value == 0:
                        value = 1
                params_xgb[param] = value

            st.write("CatBoost")
            for param, default in params_cb.items():
                if param == 'depth':
                    value = st.slider(f"{param}", None, 20, default, step=1, key=f"cb_{param}")
                    if value == 0:
                        value = None
                elif param == 'learning_rate':
                    value = st.slider(f"{param}", 0.01, 1.0, default, step=0.01, key=f"cb_{param}")
                elif param == 'l2_leaf_reg':
                    value = st.slider(f"{param}", 0, 10, default, step=1, key=f"cb_{param}")
                elif param == 'iterations':
                    value = st.slider(f"{param}", 0, 1000, default, step=10, key=f"cb_{param}")
                    if value == 0:
                        value = 1
                params_cb[param] = value

            # Display selected parameters
            st.write("Selected Parameters:")
            st.write("Gradient Boosting")
            st.write(params_gb)
            st.write("XGBoost")
            st.write(params_xgb)
            st.write("CatBoost")
            st.write(params_cb)

            params_gb['random_state'] = 42
            params_xgb['random_state'] = 42
            params_cb['random_state'] = 42

            params_cb['task_type'] = 'CPU'
            params_cb['silent'] = True

            model_gb = GradientBoostingRegressor(**params_gb)
            model_xgb = xgb.XGBRegressor(**params_xgb)
            model_cb = CatBoostRegressor(**params_cb)
            models = [model_gb, model_xgb, model_cb]
            
            for model in models:
                model.fit(X_train_combined, y_train_tc_par)
            
            for model in  models:
                print('MSE of ', model.__class__.__name__, ' on test:', metrics.mse(y_test_tc_par, model.predict(X_test_combined)))
            
            meta_model = LinearRegression()
            meta_model.fit(X_train_combined, y_train_tc_par)
            print('MSE of metaregressor on original datasets features on test: ', metrics.mse(y_test_tc_par, meta_model.predict(X_test_combined)))

            n = 5
            y_pred_tc_par, model = source.metaregressor(models, meta_model, X_train_combined, X_test_combined, y_train_tc_par, n)
            pred_all_tc_par, model = source.metaregressor(models, meta_model, X_train_combined, ALL_GIS_combined, y_train_tc_par, n)
            if pred_name is not None:
                display_title_metrics(pred_name)
                source.get_metrics(y_test_tc_par, y_pred_tc_par)

        return y_pred_tc_par, pred_all_tc_par, model
    



    if what_to_predict in ['TC_par', 'VHC']:
        if what_to_predict == 'TC_par':
            pred_name = 'TC_par'
            y_pred_tc_par, pred_all_tc_par, model_tc_par = predictor(pred_name)
            
            if ' ' in model_mode: 
                model_name = "".join(model_mode.split())
            else: 
                model_name = model_mode
            df_to_csv(pd.DataFrame({depth_name: ALL_GIS[depth_name], 
                                    'TC_par_pred': pred_all_tc_par}), 
                                    filename=model_name +'_'+'TC_par',
                                    button_text='Ð¡ÐºÐ°Ñ‡Ð°Ñ‚ÑŒ Ð¿Ñ€Ð¾Ð³Ð½Ð¾Ð· TC_par Ð¿Ð¾ Ð²ÑÐµÐ¼Ñƒ Ð¸Ð½Ñ‚ÐµÑ€Ð²Ð°Ð»Ñƒ')
        elif what_to_predict == 'VHC':
            pred_name = 'VHC'
            y_pred_vhc, pred_all_vhc, model_vhc = predictor(pred_name)

            if ' ' in model_mode: 
                model_name = "".join(model_mode.split())
            else: 
                model_name = model_mode
            df_to_csv(pd.DataFrame({depth_name: ALL_GIS[depth_name], 
                                    'VHC_pred': pred_all_vhc}), 
                                    filename=model_name +'_'+'VHC',
                                    button_text='Ð¡ÐºÐ°Ñ‡Ð°Ñ‚ÑŒ Ð¿Ñ€Ð¾Ð³Ð½Ð¾Ð· VHC Ð¿Ð¾ Ð²ÑÐµÐ¼Ñƒ Ð¸Ð½Ñ‚ÐµÑ€Ð²Ð°Ð»Ñƒ')
    elif what_to_predict in ['TC_per']:
        pred_name = 'Anisotropy'
        y_pred_anisotropy, pred_all_anisotropy, model_anisotropy = predictor(pred_name)

        if ' ' in model_mode: 
            model_name = "".join(model_mode.split())
        else: 
            model_name = model_mode
        df_to_csv(pd.DataFrame({depth_name: ALL_GIS[depth_name], 
                                'K_pred': pred_all_anisotropy}), 
                                filename=model_name +'_'+'K',
                                button_text='Ð¡ÐºÐ°Ñ‡Ð°Ñ‚ÑŒ Ð¿Ñ€Ð¾Ð³Ð½Ð¾Ð· K Ð¿Ð¾ Ð²ÑÐµÐ¼Ñƒ Ð¸Ð½Ñ‚ÐµÑ€Ð²Ð°Ð»Ñƒ')
    
        y_pred_tc_per = X_test_orig[tc_par_name].values / y_pred_anisotropy
        y_test_tc_per = data_to_pred.loc[X_test_orig.index, tc_per_name].values

        if use_lith:
            try:
                pred_all_tc_per = pred_all_tc_par / pred_all_anisotropy
            except:
                st.write(r"Ð”Ð»Ñ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð¿Ñ€Ð¾Ð³Ð½Ð¾Ð·Ð° $\lambda_{\bot}$ Ð½Ð° Ð²ÐµÑÑŒ Ð¸Ð½Ñ‚ÐµÑ€Ð²Ð°Ð», Ð·Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚Ðµ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð½Ñ‹Ð¹ Ñ€Ð°Ð½ÐµÐµ Ð¿Ñ€Ð¾Ð³Ð½Ð¾Ð· $\lambda_{\parallel}$ Ð¿Ð¾ Ð²ÑÐµÐ¼Ñƒ Ð¸Ð½Ñ‚ÐµÑ€Ð²Ð°Ð»Ñƒ:")
                uploaded_tc_par_pred = st.file_uploader("TC_par_pred", 
                                                        type=['csv', 'xlsx'], 
                                                        label_visibility='collapsed')
                pred_all_tc_par = source.load_file_to_st(uploaded_tc_par_pred)
            

            
        a = pred_all_tc_par.loc[:, pred_all_tc_par.columns != depth_name].iloc[:, 0].values
        b = pred_all_anisotropy
        pred_all_tc_per = a / b


        if ' ' in model_mode: 
            model_name = "".join(model_mode.split())
        else: 
            model_name = model_mode
        df_to_csv(pd.DataFrame({depth_name: ALL_GIS[depth_name], 
                                'TC_per_pred': pred_all_tc_per}), 
                                filename=model_name +'_'+'TC_per',
                                button_text='Ð¡ÐºÐ°Ñ‡Ð°Ñ‚ÑŒ Ð¿Ñ€Ð¾Ð³Ð½Ð¾Ð· TC_per Ð¿Ð¾ Ð²ÑÐµÐ¼Ñƒ Ð¸Ð½Ñ‚ÐµÑ€Ð²Ð°Ð»Ñƒ',
                                add_key='1')

        st.write(r"ÐœÐµÑ‚Ñ€Ð¸ÐºÐ¸ Ð´Ð»Ñ $\lambda_{\bot}$")
        source.get_metrics(y_test_tc_per, y_pred_tc_per)


    # fig, ax = plt.subplots(1, 2, figsize=(12,5))
    
    # ax[0].hist(pred_all_anisotropy, bins=20)
    # ax[1].hist(pred_all_tc_per, bins=20)

    # st.pyplot(fig)





# st.toast("Warming up...")
# st.error("Error message")
# st.warning("Warning message")
# st.info("Info message")
# st.success("Success message")


if __name__ == "__main__":
    run()